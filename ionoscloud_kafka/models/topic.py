# coding: utf-8

"""
    Event Streams for Apache Kafka API

    A managed Apache Kafka cluster is designed to be highly fault-tolerant and scalable, allowing large volumes of data to be ingested, stored, and processed in real-time. By distributing data across multiple brokers, Kafka achieves high throughput and low latency, making it suitable for applications requiring real-time data processing and analytics. 

    The version of the OpenAPI document: 1.8.0
    Contact: support@cloud.ionos.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from ionoscloud_kafka.models.topic_log_retention import TopicLogRetention
from typing import Optional, Set
from typing_extensions import Self

class Topic(BaseModel):
    """
    A topic is a category or feed name to which records are published. Topics are the way Kafka organizes messages. They act as logical channels for data streams. Topics are split into partitions, making them scalable and allowing parallelism. 
    """ # noqa: E501
    name: Optional[Annotated[str, Field(min_length=2, strict=True, max_length=63)]] = Field(default=None, description="The name of the Kafka cluster topic. Must be 63 characters or less and must begin and end with an alphanumeric character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between. ")
    replication_factor: Optional[Annotated[int, Field(strict=True, ge=1)]] = Field(default=None, description="The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka cluster. ", alias="replicationFactor")
    number_of_partitions: Optional[Annotated[int, Field(strict=True, ge=1)]] = Field(default=None, description="The number of partitions of the topic. Partitions allow for parallel processing of messages. ", alias="numberOfPartitions")
    log_retention: Optional[TopicLogRetention] = Field(default=None, alias="logRetention")
    __properties: ClassVar[List[str]] = ["name", "replicationFactor", "numberOfPartitions", "logRetention"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Topic from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of log_retention
        if self.log_retention:
            _dict['logRetention'] = self.log_retention.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Topic from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "name": obj.get("name"),
            "replicationFactor": obj.get("replicationFactor"),
            "numberOfPartitions": obj.get("numberOfPartitions"),
            "logRetention": TopicLogRetention.from_dict(obj["logRetention"]) if obj.get("logRetention") is not None else None
        })
        return _obj


